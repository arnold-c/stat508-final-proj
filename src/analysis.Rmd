---
title: "STAT 508 Final Project Analysis"
author: "Callum Arnold"
output:
    html_notebook:
        code_folding: hide
        toc: yes
        toc_float: yes
---

# Set Up

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.width = 14)
```

```{r}
library(tidyverse)
library(tidymodels)
library(themis)
library(kknn)
library(here)
library(kableExtra)
library(hrbrthemes)
library(janitor)

RNGkind(sample.kind = "Rounding")
set.seed(1)

theme_set(theme_ipsum())
```

```{r}
credit <- as_tibble(read_csv(here("data", "creditcard.csv")))
```

```{r}
credit <- credit %>%
  mutate(
    log_amount = log(Amount + 1),
    Class = case_when(
      Class == 0 ~ "None",
      Class == 1 ~ "Fraud"
    )
  ) %>%
  mutate(across(.cols = Class, .fns = factor)) %>%
  select(-Amount)
```


```{r}
tabyl(credit$Class)
```

# Pre-Processing

Because there's a severe class imbalance, we should use subsampling (either oversampling or undersampling).

Subsampling has a few important points regarding the [workflow](https://www.tidymodels.org/learn/models/sub-sampling/):

- It is extremely important that subsampling occurs inside of resampling. Otherwise, the resampling process can produce poor estimates of model performance.
- The subsampling process should only be applied to the analysis set. The assessment set should reflect the event rates seen “in the wild” and, for this reason, the skip argument to step_downsample() and other subsampling recipes steps has a default of TRUE.

```{r}
set.seed(1234)
credit_split <- initial_split(credit, strata = "Class", prop = 0.8)

credit_train <- training(credit_split)
credit_test <- testing(credit_split)

tabyl(credit_train$Class)
tabyl(credit_test$Class)
```


```{r}
credit_rec <- 
  recipe(Class ~ ., data = credit_train) %>%
  step_downsample(Class) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_zv(all_numeric()) %>%
  step_normalize(Time, log_amount) %>%
  prep()
```

```{r}
juice(credit_rec) %>% count(Class)
```

```{r}
knn_spec <- nearest_neighbor() %>%
  set_engine("kknn") %>%
  set_mode("classification")

knn_fit <- knn_spec %>%
  fit(
    Class ~ .,
    data = juice(credit_rec)
    )

knn_fit
```

```{r}
tree_spec <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

tree_fit <- tree_spec %>%
  fit(
    Class ~ .,
    data = juice(credit_rec)
  )

tree_fit
```

# Evaluate Models

```{r}
set.seed(1234)
validation_splits <- mc_cv(juice(credit_rec), prop = 0.8, strata = "Class")
```

```{r}
knn_result <- fit_resamples(
  knn_spec,
  Class ~ .,
  validation_splits,
  control = control_resamples(save_pred = TRUE)
)

knn_result %>%
  collect_metrics()
```

```{r}
tree_result <- fit_resamples(
  tree_spec,
  Class ~ .,
  validation_splits,
  control = control_resamples(save_pred = TRUE)
)

tree_result %>%
  collect_metrics()
```

```{r}
knn_result %>%
  unnest(.predictions) %>%
  mutate(model = "kknn") %>%
  bind_rows(
    tree_result %>%
  unnest(.predictions) %>%
  mutate(model = "rpart")
  ) %>%
  group_by(model) %>%
  roc_curve(Class, .pred_Fraud) %>%
  autoplot()

```

```{r}
knn_result %>%
  unnest(.predictions) %>%
  conf_mat(Class, .pred_class)

tree_result %>%
  unnest(.predictions) %>%
  conf_mat(Class, .pred_class)
```

```{r}
tree_fit %>%
  predict(new_data = credit_test, type = "prob") %>%
  mutate(truth = credit_test$Class) %>%
  roc_auc(truth, .pred_Fraud)
```


<!-- # Test Modelling -->
<!-- ## Oversampling -->

<!-- For oversampling, we'll use the ROSE (random over sampling examples) method  -->
<!-- [Menardi, G. and Torelli, N. (2014)](https://link.springer.com/article/10.1007/s10618-012-0295-5). -->

<!-- ## Logistic -->

<!-- ```{r} -->
<!-- set.seed(1) -->
<!-- cv_folds <- vfold_cv(credit, strata = "Class", repeats = 5) -->

<!-- cls_metrics <- metric_set(roc_auc, j_index) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- log_mod <-  -->
<!--   logistic_reg() %>%  -->
<!--   set_engine("glm") -->
<!-- ``` -->

<!-- ```{r} -->
<!-- log_rose_wflw <-  -->
<!--   workflow() %>%  -->
<!--   add_model(log_mod) %>%  -->
<!--   add_recipe(credit_rec) -->

<!-- log_rose_wflw -->
<!-- ``` -->

<!-- ```{r} -->
<!-- log_wflw <-  -->
<!--   workflow() %>%  -->
<!--   add_model(log_mod) %>%  -->
<!--   add_formula(Class ~ .) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- set.seed(2180) -->

<!-- log_rose_res <- fit_resamples( -->
<!--   log_rose_wflw,  -->
<!--   resamples = cv_folds,  -->
<!--   metrics = cls_metrics -->
<!-- ) -->

<!-- collect_metrics(log_rose_res) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- set.seed(2180) -->

<!-- log_only_res <- fit_resamples( -->
<!--   log_wflw, -->
<!--   resamples = cv_folds, -->
<!--   metrics = cls_metrics -->
<!-- ) -->

<!-- collect_metrics(log_only_res) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- no_sampling <-  -->
<!--   log_only_res %>%  -->
<!--   collect_metrics(summarize = FALSE) %>%  -->
<!--   dplyr::select(-.estimator) %>%  -->
<!--   mutate(sampling = "no_sampling") -->

<!-- with_sampling <-  -->
<!--   log_rose_res %>%  -->
<!--   collect_metrics(summarize = FALSE) %>%  -->
<!--   dplyr::select(-.estimator) %>%  -->
<!--   mutate(sampling = "rose") -->

<!-- bind_rows(no_sampling, with_sampling) %>%  -->
<!--   mutate(label = paste(id2, id)) %>%   -->
<!--   ggplot(aes(x = sampling, y = .estimate, group = label)) +  -->
<!--   geom_line(alpha = .4) +  -->
<!--   facet_wrap(~ .metric, scales = "free_y") -->
<!-- ``` -->

